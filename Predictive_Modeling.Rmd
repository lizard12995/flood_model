---
title: "Modeling Flood Inundation in Calgary and Edmonton"
author: "Lizzie & Devon"
date: "3/20/2023"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    code_download: true
---

```{r setup, include=FALSE,message = FALSE,cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(knitr)
```


# 1. Introduction

Urban flooding is a complicated issue that requires special care. Flooding, especially in low-lying locations and near rivers, can have devastating consequences for communities, including loss of life and property. With meteorological events growing in severity under climate change, we must prepare our communities for the possibility of flooding by understanding why inundation occurs where it does and using that information to predict where inundation might occur in cities where existing flooding data is scarce. In an ideal world, every community would have a Flooding Modeling & Planning Center in-house, or access to one at the regional or state level, that possesses the data and modeling capacity to predict future inundation based on past events and present conditions. 

We had data on past flooding events within Calgary, a Canadian city that experiences riverine flooding during major storm events. Calgary is the largest city in Alberta, a plains province, and home to the nation's lucrative oil and gas industries. We gathered data on Calgary and developed a model that could potentially predict flooding in its distance twin city, Edmonton, located further north in Alberta with a slightly lower population (Calgary proper hosts about 1.4 million people in a 1.5 million-person metro area while Edmonton hosts about 1.1 million people in a 1.4 million-person metro area). In Calgary, the Bow River bisects the community, running through its central districts, with significant development on either side. In Edmonton, the North Saskatchewan River bisects it, with creeks and lakes running in the northwest. Because of these similarities, we decided to use the data we had available for Calgary, including Elevation, Land Cover, and hydrographic features both found and derived to predict inundation patterns in Edmonton. The two are often studied together as part of a megaregion, with the smaller city of Red Deer roughly equidistant between the them.


## 1.1. Setup - Collecting all the packages we might utilize


```{r libraries, warning = FALSE, message = FALSE}
library(caret)
library(pscl)
library(plotROC)
library(pROC)
library(sf)
library(tidyverse)
library(knitr)
library(kableExtra)
library(tigris)
library(viridis)
library(sfdep)
```


```{r mapTheme, echo=TRUE}
mapThemec <- theme(plot.title =element_text(size=12),
                  plot.subtitle = element_text(size=8),
                  plot.caption = element_text(size = 6),
                  axis.line=element_blank(),
                  axis.text.x=element_blank(),
                  axis.text.y=element_blank(),
                  axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank(),
                  panel.background=element_blank(),
                  panel.border=element_blank(),
                  panel.grid.major=element_line(colour = 'transparent'),
                  panel.grid.minor=element_blank(),
                  legend.direction = "vertical", 
                  legend.position = "right",
                  plot.margin = margin(1, 1, 1, 1, 'cm'),
                  legend.key.height = unit(1, "cm"), legend.key.width = unit(0.2, "cm"))

plotThemec <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.75),
  axis.ticks=element_blank())
```


#LOAD FISHNET DATA

We gather open data from both Calgary’s open data site (https://data.calgary.ca/) and Edmonton's open data site.

Variables we are considering are:
- Percent Impermeable Surface (imp): a measure of how much surface within a fishnet square is impermeable. We gathered land cover data for both Calgary and Edmonton and reclassified the land cover options as either permeable (0) or impermeable (1). We hypothesize that more impermeable surface will lead to a higher likelihood of inundation, all else held constant, because the water cannot permeate underground.
- Mean Impermeable Surface of Nearest Neighbors (nn_imp): in R, we performed nearest neighbors analysis to affix the mean percentage of impermeable surface of each fishnet square's 8 nearest neighbors. We hypothesize that more impermeable surface in the nearest neighbors will lead to a higher likelihood of inundation, all else held constant, because the water cannot permeate underground in that vicinity.
- Distance to Stream/Water Feature (dist_stream): we calculated the nearest distance a fishnet square observes to a stream/water feature in ArcGIS. We hypothesize that the closer a feature is to a water feature, the more likely it is to observe inundation, because the overtopping of existing water features results in water spilling into nearby geographies. We considered log transforming this feature, but doing so results in problems at the 0 bound.
- Maximum Slope Value (max_slope): we calculated the maximum slope observed within a fishnet square using zonal statistics from our DEM. We hypothesize that the higher the slope (in degrees) observed in a fishnet square, the less likely it is to experience inundation, because water can more easily run off of surfaces that are at a more extreme slope.
- Mean Maximum Slope Value of Nearest Neighbors (nn_slope): in R, we performed nearest neighbors analysis to affix the mean max_slope value of the 8 nearest neighbors to a given fishnet square to that fishnet square. We hypothesize that the higher the nn_slope, the less likely it is to experience inundation, because higher neighborhood slope values suggest a larger surface of extreme slopes where water can run off. 
- Difference between nn_slope and max_slope (slope_diff): we consider the different between the nearest neighbors mean of maximum slope and the maximum slope of the given fishnet square in case there are extreme discrepancies between the two that may be flattened in nearest neighbors analysis. We hypothesize that the higher the difference, the higher the likelihood of inundation, because there is a significantly flatter surface that will observe inundation from the sloped surfaces nearby.
- Mean elevation of a fishnet square (mean_elev): we have the DEM, so we take the mean elevation within the fishnet square as the meaningful measure of center. We hypothesize that the higher the mean elevation, the less likely the square is to observe inundation, because water will runoff down sloped surfaces towards the areas of lowest elevation. To mitigate inherent differences in elevation between Calgary and Edmonton, we do log transform this variable. 
- Mean of log mean elevation of the 8 nearest neighbors (nn_log_mean_elev): we performed nearest neighbors analysis to get the spatial lag for log mean elevation in each city, with the expectation that the higher the value, the higher the likelihood of inundation due to its inherent higher elevation. Low-lying areas, especially near riverbanks, are likeliest to flood.


```{r}
calgary<-st_read("MidtermData/Processed/Calg_Clip.shp")
city_bounds <- st_read("MidtermData/Calgary/CALGIS_CITYBOUND_LIMIT/CALGIS_CITYBOUND_LIMIT.shp")

names(calgary) <- c("length", "imp", "nn_imp", "dist_stream", "max_slope", "nn_slope", "slope_diff", "mean_elev", "shp1","shp2", "inundation_value",  "geometry")

calgary <- calgary %>%
  rowid_to_column("Id")

```

# 3. Exploratory

## 3.1. Maps

Here, we see the boundaries of Calgary as well as the bounds of our fishnet study area.

```{r first_plot, warning = FALSE, message = FALSE}
ggplot() +
  geom_sf(data = city_bounds)+
  geom_sf(data = calgary, 
          fill = "dark green", 
          color = "dark green",
          alpha = 0.6) +
  labs(title="Calgary City Bounds and Fishnet Bounds") +
  mapThemec
```

Here, we can see what previous inundation within the fishnet study area has looked like. Inundation is classified as areas where the percent of the fishnet square that was inundated is greater than zero.

```{r plot_fishnet}

calgary <- calgary %>%
  filter(mean_elev >0) %>%
  mutate(inundation = ifelse(inundation_value > 0, 1,0),
         log_mean_elev = log(mean_elev),
      nb = st_knn(geometry, k=8),
      wt = st_weights(nb),
      nn_log_mean_elev = st_lag(log_mean_elev,nb,wt),
      elev_diff = log_mean_elev - nn_log_mean_elev)


ggplot() + 
  geom_sf(data=calgary, aes(fill=inundation), color = "transparent") +
  labs(title="Calgary (Fishnet)") +
  mapThemec

```

## 3.2. Plots

Here we have built some bar plots that show differences in our independent variables across land that has and has not flooded.

We can examine some of the variables and how they vary across our inundated/not inundated variable. 

```{r wide_2_long}

calgaryPlotVariables <- 
  calgary %>%
  as.data.frame() %>%
  select("imp", "nn_imp", "dist_stream", "max_slope", "nn_slope", "slope_diff", "log_mean_elev", "nn_log_mean_elev", "elev_diff", "inundation") %>%
  gather(variable, value, -inundation)

ggplot(calgaryPlotVariables %>%
         group_by(inundation, variable) %>%
         summarize(mean = mean(value))) + 
     geom_bar(aes(as.factor(inundation), 
                  mean, 
                  fill=as.factor(inundation)),
              stat="identity") + 
     facet_wrap(~variable, scales = "free") +
     scale_fill_manual(values = c("dark green", "dark blue"),
                      labels = c("Not Inundated","Inundated"),
                      name = "") +
    labs(x="Inundated", y="Value")
```


```{r violin_plot, eval=FALSE}
ggplot(calgaryPlotVariables) + 
     geom_violin(aes(x = as.factor(inundation), 
                  y = value, fill = as.factor(inundation))) + 
     facet_wrap(~variable, scales = "free") +
     labs(x="Inundated", y="Value") + 
     scale_fill_manual(values = c("dark green", "dark blue"),
     labels = c("Not Inundated","Inundated"), name = "") +
     labs(x="Inundated", y="Value") + 
  plotThemec
```

# 4. Data wrangling

Select only the variables we want to analyze. 

```{r}
calgary2 <- 
  calgary %>%
  select(imp, nn_imp, dist_stream, max_slope, nn_slope, slope_diff, log_mean_elev, nn_log_mean_elev, elev_diff, inundation, Id) %>%
  st_drop_geometry()

```

# 5. Model building

## 5.1. Partition training and test sets

Now we create training and test sets. 

We set `p` to .7 - a 70% training set and 30% test set.


```{r training_set}
set.seed(3456)
trainIndex <- createDataPartition(calgary2$inundation, p = .70,
                                  list = FALSE,
                                  times = 1)

calgTrain <- calgary2[ trainIndex,]
calgTest  <- calgary2[-trainIndex,]
```

## 5.2. Make a binomial model

Now let’s estimate a logistic regression model. 

```{r firstModel, warning = FALSE, message = FALSE}

calgModel <- glm(inundation ~ .,
                    family="binomial"(link="logit"), 
                 data = calgTrain %>%
                   select(-Id))

summary(calgModel)

```

## 5.3. Model validation

Using the `predict` function, we create a vector of classification probabilities we call `classProbs`. These are the predicted probability of a test set (`calgTest`) fishnet cell being conserved conditional on our model. Setting the parameter `type="reponse"` returns probabilities that range from 0 to 1.

```{r predict_first}
classProbs <- predict(calgModel, calgTest, type="response")

hist(classProbs)
```

Let’s put `classProbs` into a data frame along with the observed `preserve` outome, which is either `1` for preserved land or `0` for unpreserved.

Then we build this funky plot, `testProbsPlot`. The vertical line represents a 0.5 probability of inundation.

```{r plot_preds}
testProbs <- data.frame(obs = as.numeric(calgTest$inundation),
                        pred = classProbs)

ggplot(testProbs, aes(x = pred, fill=as.factor(obs))) + 
  geom_density() +
  facet_grid(obs ~ .) + 
  xlab("Probability") +
  ylab("Frequency")+
  geom_vline(xintercept = .5) +
  scale_fill_manual(values = c("dark green", "dark blue"),
                      labels = c("Not Inundated","Inundated"),
                      name = "")+
  plotThemec
```

### 5.3.1 Confusion metrics

Let’s choose 35% and then create a table of our correct and incorrect predictions, called a "confusion matrix". Below we set the reference to the observed preserved status, data to the predicted outcome, and make sure to state which factor level is the positive (ie. inundated) level. 

```{r confusion_matrix, message = FALSE, warning = FALSE}
testProbs$predClass  = ifelse(testProbs$pred > .35 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass), 
                       positive = "1")
```


**1. Sensitivity - the proportion of actual positives (1’s) that were predicted to be positive. Also known as “true positive rate”.**

**2. Specificity - The proportion of actual negatives (0’s) that were predicted to be negatives. Also known as “true negative rate”.**

### 5.3.2. ROC Curve


```{r roc_curve, message = FALSE, warning = FALSE}

ggplot(testProbs, aes(d = obs, m = pred)) + 
  geom_roc(n.cuts = 50, labels = FALSE) + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') 

```

Area under the curve:

```{r auc, warning = FALSE}
auc(testProbs$obs, testProbs$pred)
```

### 5.3.3. Cross validation

100 fold cross-validation:

```{r k_fold, warning = FALSE, message = FALSE}
ctrl <- trainControl(method = "cv", 
                     number = 100, 
                     p = 0.7, 
                     savePredictions = TRUE)

cvFit <- train(as.factor(inundation) ~ .,  data = calgary2 %>% 
                                                as.data.frame() %>%
                                                select(-Id), 
               method="glm", family="binomial",
               trControl = ctrl)

cvFit
```

Let’s plot a histogram of accuracy across all 100 folds.

```{r cv_hist, warning = FALSE, message = FALSE}
ggplot(as.data.frame(cvFit$resample), aes(Accuracy)) + 
  geom_histogram() +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Accuracy",
       y="Count")+
  plotThemec
```


### 5.3.2. Map predictions

Now that we have tuned our model, let’s run it on our test set.

```{r predict_whole, warning = FALSE, message= FALSE}
allPredictions <- 
  predict(cvFit, calgary, type="prob")[,2]
  
calgary3 <- 
  cbind(calgary,allPredictions) %>%
  mutate(allPredictions = round(allPredictions * 100, digits = 2))

```

Now we map the predictions.

```{r predicted_map1, warning = FALSE, message = FALSE}
 ggplot() + 
    geom_sf(data=calgary3, aes(fill=factor(ntile(allPredictions,5))), 
            colour=NA) +
    scale_fill_manual(values = c("#edf8fb","#b3cde3","#8c96c6","#8856a7","#810f7c"),
                      labels=as.character(quantile(calgary3$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  mapThemec +
  labs(title="")
```

Mapping again with previous inundation:

```{r predicted_map2, warning = FALSE, message = FALSE}
 ggplot() + 
  geom_sf(data=calgary, aes(fill=factor(ntile(allPredictions,5))), colour=NA) +
  scale_fill_manual(values = c("#edf8fb","#b3cde3","#8c96c6","#8856a7","#810f7c"),
                    labels=as.character(quantile(calgary3$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                    name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  geom_sf(data=calgary  %>% 
               filter(inundation == 1), 
               fill="dark blue", colour=NA) +
  mapThemec +
  labs(title="Observed and Predicted Inundation",
       subtitle="Calgary; Previous inundation in Blue")
```

We could assess many things about our model by exploring our errors.

Let's map our confusion metrics across our entire data set for a 15% threshold. 

```{r error_map, warning = FALSE, message= FALSE}

thresh <- 15

calgary3 %>%
  mutate(confResult=case_when(allPredictions < thresh & inundation==0 ~ "True_Negative",
                              allPredictions >= thresh & inundation==1 ~ "True_Positive",
                              allPredictions < thresh & inundation==1 ~ "False_Negative",
                              allPredictions >= thresh & inundation==0 ~ "False_Positive")) %>%
  ggplot()+
  geom_sf(aes(fill = confResult), color = "transparent")+
  scale_fill_manual(values = c("Red","Orange","Light Blue","Light Green"),
                    name="Outcomes")+
  labs(title="Confusion Metrics") +
  mapThemec

```

Finally, let's try out our model on Edmonton!

#bringing in Edmonton data, matching data projection, and clipping extent to city boundaries
edmonton<-st_read("C:\\Users\\dchod\\OneDrive\\Documents\\GradY2\\Modeling\\Midterm\\Attempt5\\edmnet41.shp")
ecity_bounds<-st_read("C:\\Users\\dchod\\OneDrive\\Documents\\GradY2\\Modeling\\Midterm\\Edmonton\\geo_export_dc7e3693-8d53-4ccf-bd29-36255ee87cf6.shp")
st_geometry(edmonton) <- "geometry"
ecity_bounds <- st_transform(ecity_bounds, crs = st_crs(edmonton))
edmonton <- st_intersection(edmonton, ecity_bounds)

#plotting the Edmonton fishnet
ggplot() +
  geom_sf(data = ecity_bounds)+
  geom_sf(data = edmonton, 
          fill = "dark green", 
          color = "dark green",
          alpha = 0.6) +
  labs(title="Edmonton City Bounds and Fishnet Bounds") +
  mapThemec

#renaming columns,adding log transformed variables
edmonton <- rename(edmonton, imp=MEAN_1, dist_stream=diststream, mean_elev=MEAN, max_slope=MAX)

# pulling out polygon and identifiers to reattach later
edm_poly <- edmonton%>% 
  select(OBJECTID, geometry)

#performing nearest neighbor operation to get additional independent variables
edmonton <- st_centroid(edmonton)
knn <- st_knn(edmonton, k = 8)
nn_indices <- knn$nn_index
wt <- knn$nn_dist
edmonton <- edmonton %>%
  filter(mean_elev >0) %>%
  mutate(log_mean_elev = log(mean_elev),
         nb = st_knn(geometry, k=8),
         wt = st_weights(nb),
         nn_log_mean_elev = st_lag(log_mean_elev,nb,wt),
         nn_slope = st_lag(max_slope,nb,wt),
         nn_imp = st_lag(imp,nb,wt),
         slope_diff = nn_slope - max_slope,
         elev_diff = log_mean_elev - nn_log_mean_elev)

#developing a dataframe that only has the variables of interest
edmonton2 <- 
  edmonton %>%
  select(imp, dist_stream, max_slope, nn_slope, slope_diff, log_mean_elev, nn_log_mean_elev, elev_diff, OBJECTID_2,nn_imp)%>%
  st_drop_geometry()
edmonton2 <- rename(edmonton2, OBJECTID=OBJECTID_2)

#using the predict command with Edmonton data
edm_predictions <- predict(calgModel, newdata = edmonton2, type = "response")
summary(edm_predictions)
hist(edm_predictions)
allPredictions <- 
  predict(cvFit, edmonton2,type="prob")[,2]

fishnet_df <- 
  cbind(edmonton2,allPredictions)%>%
  st_drop_geometry()

fishnet_df <- fishnet_df %>%
  left_join(edm_poly, by="OBJECTID")

st_geometry(fishnet_df) <- "geometry"

#plotting the predicted values based on the Calgary model
ggplot() +
  geom_sf(data=fishnet_df, aes(fill=factor(ntile(allPredictions,5))),
          colour=NA) +
  scale_fill_manual(values = c("#edf8fb","#b3cde3","#8c96c6","#8856a7","#810f7c"),
                    labels=as.character(quantile(fishnet_df$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                    name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  mapThemec +
  labs(title="")

