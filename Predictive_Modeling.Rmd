---
title: "Modeling Flood Inundation in Calgary and Edmonton"
author: "Lizzie & Devon"
date: "3/20/2023"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    code_download: true
---

```{r setup, include=FALSE,message = FALSE,cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(knitr)
```


# 1. Introduction


## 1.1. Setup


```{r libraries, warning = FALSE, message = FALSE}
library(caret)
library(pscl)
library(plotROC)
library(pROC)
library(sf)
library(tidyverse)
library(knitr)
library(kableExtra)
library(tigris)
library(viridis)
```


```{r mapTheme, echo=TRUE}
mapTheme <- theme(plot.title =element_text(size=12),
                  plot.subtitle = element_text(size=8),
                  plot.caption = element_text(size = 6),
                  axis.line=element_blank(),
                  axis.text.x=element_blank(),
                  axis.text.y=element_blank(),
                  axis.ticks=element_blank(),
                  axis.title.x=element_blank(),
                  axis.title.y=element_blank(),
                  panel.background=element_blank(),
                  panel.border=element_blank(),
                  panel.grid.major=element_line(colour = 'transparent'),
                  panel.grid.minor=element_blank(),
                  legend.direction = "vertical", 
                  legend.position = "right",
                  plot.margin = margin(1, 1, 1, 1, 'cm'),
                  legend.key.height = unit(1, "cm"), legend.key.width = unit(0.2, "cm"))

plotTheme <- theme(
  plot.title =element_text(size=12),
  plot.subtitle = element_text(size=8),
  plot.caption = element_text(size = 6),
  axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
  axis.text.y = element_text(size = 10),
  axis.title.y = element_text(size = 10),
  # Set the entire chart region to blank
  panel.background=element_blank(),
  plot.background=element_blank(),
  #panel.border=element_rect(colour="#F0F0F0"),
  # Format the grid
  panel.grid.major=element_line(colour="#D0D0D0",size=.75),
  axis.ticks=element_blank())
```


#LOAD FISHNET DATA

Prep ahead of this:
Gather open data from both Calgary’s open data site (https://data.calgary.ca/ Links to an external site.) and your comparable city’s open data site as well as other internet sources.

Using what we’ve learned about feature engineering over the first part of the semester, build as many useful variables describing the natural, hydrological and built environment features that might help explain flood inundation. Form a hypothesis to motivate your search for data. You might hypothesize that "the probability of a grid cell to flood is a function of _________" and then find or engineer a feature that turns that hypothesis into a model-able parameter. You must include at least one feature from the watershed analysis.

Uplaod here:

```{r load_data, warning = FALSE, message = FALSE, results = "hide"}
preserve <- st_read()
```

Let's project it to [something]

```{r transform}

```

# 3. Exploratory

## 3.1. Maps

Let's plot the sf object.

```{r first_plot, warning = FALSE, message = FALSE}
ggplot() +
  geom_sf(data = counties)+
  geom_sf(data=protected, 
          fill = "dark green", 
          color = "dark green",
          alpha = 0.6) +
  labs(title="Protected lands in Pennsylvania") +
  mapTheme
```

Now let’s plot the fishnet version. 

Notice we set the `fill` of our `geom_sf` to `as.factor(preserve)` and set the color to "transparent" outside the aesthetics. What does this do?


```{r plot_fishnet}
ggplot() + 
  geom_sf(data=preserve, aes(fill=as.factor(preserve)), color = "transparent") +
  geom_sf(data = counties, fill = "transparent", color = "white")+
  scale_fill_manual(values = c("dark blue", "dark green"),
                    labels = c("Not Preserved","Preserved"),
                    name = "") +
  labs(title="Protected lands in Pennsylvania (Fishnet)") +
  mapTheme
```

## 3.2. Plots

Let’s build some bar plots that show differences in our independent variables across land that has and has not flooded.

Notice the use of the `gather` function. What is it doing? Use `glimpse` to examine the data.

```{r wide_2_long}
preservePlotVariables <- 
  preserve %>%
  as.data.frame() %>%
  select(preserve,elevation,slope,dSteepSlop,dUrban,distRivers) %>%
  gather(variable, value, -preserve)
```


Let's examine some of the variables and how they vary across our flooded/not flooded variable. Our `preservePlotVariables` data frame has rows for each cell-variable pair, we `group_by` variable and preservation status and take the mean value for each variable by status.

```{r eda_by_status}
ggplot(preservePlotVariables %>%
         group_by(preserve, variable) %>%
         summarize(mean = mean(value))) + 
     geom_bar(aes(as.factor(preserve), 
                  mean, 
                  fill=as.factor(preserve)),
              stat="identity") + 
     facet_wrap(~variable) +
     scale_fill_manual(values = c("dark blue", "dark green"),
                      labels = c("Not Preserved","Preserved"),
                      name = "") +
    labs(x="Preserved", y="Value")
```

*Bonus - check out this code - another way to examine these data, what do you see here that might inform a model?*

```{r violin_plot, eval=FALSE}
ggplot(preservePlotVariables) + 
     geom_violin(aes(x = as.factor(preserve), 
                  y = value, fill = as.factor(preserve))) + 
     facet_wrap(~variable, scales = "free") +
     labs(x="Preserved", y="Value") + 
     scale_fill_manual(values = c("dark blue", "dark green"),
     labels = c("Not Preserved","Preserved"), name = "") +
     labs(x="Preserved", y="Value") + 
  plotTheme
```

# 4. Data wrangling

Select only the variables we want to analyze. 

```{r}
preserve <- 
  preserve %>%
  select(preserve,elevation,slope,dSteepSlop,landCover,dUrban,distRivers, Id) 

```

# 5. Model building

## 5.1. Partition training and test sets

Now we create training and test sets. 

Let's look over this operation:

- `set.seed` generates a random number

- `createDataPartition` randomly separates our data into two sets. We set `p` to .7 - a 70% training set and 30% test set.

- QUESTION - do we train on ALL of Calgary and then TEST on another city? Or train/test on Calgary, then test on another city?

```{r training_set}
set.seed(3456)
trainIndex <- createDataPartition(preserve$landCover, p = .70,
                                  list = FALSE,
                                  times = 1)

preserveTrain <- preserve[ trainIndex,]
preserveTest  <- preserve[-trainIndex,]
```

## 5.2. Make a binomial model

Now let’s estimate a logistic regression model. The binomial logit model runs in the `glm` function (generalized linear models). We specify the dependent variable as `preserve` and run the model on our training set `preserveTrain`.

Note how we can use the dplyr pipes right in the data parameter. We have to convert to a data frame because R won’t know how to run a regression on an sf.

Let's look at the model output, we see that we have coefficients, and p-values, but no R-squared. There are other goodness of fit metrics we will look at. The AIC, though not on a 0-1 scale like R-squared, has a similar function in that it tells you about overall model fit, but not about error and accuracy.

We are not really interested in our coefficients other than their magnitude, directionality and p-value (generall). But for the record, the way the coefficients in a logistic regression are interpreted is different than in OLS - we are talking in terms of "odds" of an outcome occurring (in our case odds of land being preserved.). If we exponentiate the coefficient (`exp()`) we can interpret it as *all else equal* the exponentiated value being the increase or decrease in the odds of the outcome.

```{r firstModel, warining = FALSE, message = FALSE}
preserveModel <- glm(preserve ~ ., 
                    family="binomial"(link="logit"), data = preserveTrain %>%
                                                            as.data.frame() %>%
                                                            select(-geometry, -Id))
summary(preserveModel)

```

## 5.3. Model validation

Using the `predict` function, we create a vector of classification probabilities we call `classProbs`. These are the predicted probability of a test set (`preserveTest`) fishnet cell being conserved conditional on our model. Setting the parameter `type="reponse"` returns probabilities that range from 0 to 1.

```{r predict_first}
classProbs <- predict(preserveModel, preserveTest, type="response")

hist(classProbs)
```

Let’s put `classProbs` into a data frame along with the observed `preserve` outome, which is either `1` for preserved land or `0` for unpreserved.

Then we build this funky plot, `testProbsPlot`. The vertical line represents a 0.5 probability of preservation.

```{r plot_preds}
testProbs <- data.frame(obs = as.numeric(preserveTest$preserve),
                        pred = classProbs)

ggplot(testProbs, aes(x = pred, fill=as.factor(obs))) + 
  geom_density() +
  facet_grid(obs ~ .) + 
  xlab("Probability") +
  ylab("Frequency")+
  geom_vline(xintercept = .5) +
  scale_fill_manual(values = c("dark blue", "dark green"),
                      labels = c("Not Preserved","Preserved"),
                      name = "")+
  plotTheme
```

### 5.3.1 Confusion metrics

Let’s (arbitrarily for now) choose 50% and then create a table of our correct and incorrect predictions, called a "confusion matrix". Below we set the reference to the observed preserved status, data to the predicted outcome, and make sure to state which factor level is the positive (ie. preserved) level. Note that `confusionMatrix` does not take numeric inputs, only factors.

```{r confusion_matrix, message = FALSE, warning = FALSE}
testProbs$predClass  = ifelse(testProbs$pred > .5 ,1,0)

caret::confusionMatrix(reference = as.factor(testProbs$obs), 
                       data = as.factor(testProbs$predClass), 
                       positive = "1")
```


**1. Sensitivity - the proportion of actual positives (1’s) that were predicted to be positive. Also known as “true positive rate”.**

**2. Specificity - The proportion of actual negatives (0’s) that were predicted to be negatives. Also known as “true negative rate”.**

### 5.3.2. ROC Curve

Let's create an ROC (receiver operating characteristic) curve. What does this tell us? 

See Appendix 1 for more on ROC curves.

```{r roc_curve, message = FALSE, warning = FALSE}

ggplot(testProbs, aes(d = obs, m = pred)) + 
  geom_roc(n.cuts = 50, labels = FALSE) + 
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') 
```

How about the area under the curve?

```{r auc, warning = FALSE}
auc(testProbs$obs, testProbs$pred)
```

### 5.3.3. Cross validation

Testing the power of your model on out of sample data is critical to the machine learning process. Cross-validation iteratively creates many randomly generated test sets or ‘folds’, testing the power of your model on each.

Make sure that you update the regression to the model you specified above.

```{r k_fold, warning = FALSE, message = FALSE}
ctrl <- trainControl(method = "cv", 
                     number = 100, 
                     p = 0.7, 
                     savePredictions = TRUE)

cvFit <- train(as.factor(preserve) ~ .,  data = preserve %>% 
                                                as.data.frame() %>%
                                                select(-geometry, -Id), 
               method="glm", family="binomial",
               trControl = ctrl)

cvFit
```

Notice that the accuracy metric is actually the average accuracy across all 100 folds. While that is useful, what we are really interested in is the variability of accuracy across all 100 folds. Before going any further into that, let’s plot a histogram of accuracy across all 100 folds.

Before doing so, check out `cvFit$resample`. What information is stored here?

```{r cv_hist, warning = FALSE, message = FALSE}
ggplot(as.data.frame(cvFit$resample), aes(Accuracy)) + 
  geom_histogram() +
  scale_x_continuous(limits = c(0, 1)) +
  labs(x="Accuracy",
       y="Count")+
  plotTheme
```


### 5.3.2. Map predictions

Now that we have tuned our model, let’s predict for another city and assess our predictions.

```{r predict_whole, warning = FALSE, message= FALSE}
allPredictions <- 
  predict(cvFit, preserve, type="prob")[,2]
  
preserve <- 
  cbind(preserve,allPredictions) %>%
  mutate(allPredictions = round(allPredictions * 100)) 
```

Now we map the predictions.

```{r predicted_map1, warning = FALSE, message = FALSE}
 ggplot() + 
    geom_sf(data=preserve, aes(fill=factor(ntile(allPredictions,5))), 
            colour=NA) +
    scale_fill_manual(values = c("#edf8fb","#b3cde3","#8c96c6","#8856a7","#810f7c"),
                      labels=as.character(quantile(preserve$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                      name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  mapTheme +
  labs(title="")
```

Let’s map it again with the other land cover types overlaid. [Do we need to do this?]

```{r predicted_map2, warning = FALSE, message = FALSE}
 ggplot() + 
  geom_sf(data=preserve, aes(fill=factor(ntile(allPredictions,5))), colour=NA) +
  scale_fill_manual(values = c("#edf8fb","#b3cde3","#8c96c6","#8856a7","#810f7c"),
                    labels=as.character(quantile(preserve$allPredictions,
                                                 c(0.1,.2,.4,.6,.8),
                                                 na.rm=T)),
                    name="Predicted\nProbabilities(%)\n(Quintile\nBreaks)") +
  geom_sf(data=preserve  %>% 
               filter(preserve == 1), 
               fill="dark green",colour=NA) +
  geom_sf(data=preserve %>% 
              filter(landCover == 2), 
            fill="red",colour=NA) +  
  mapTheme +
  labs(title="Observed and Predicted Conservation Areas",
       subtitle="Pennsylvania; Existing conserved land in green; Existing development in red ")
```

We could assess many things about our model by exploring our errors.

Let's map our confusion metrics across our entire data set for a 50% threshold. 

```{r error_map, warning = FALSE, message= FALSE}
preserve %>%
  mutate(confResult=case_when(allPredictions < 50 & preserve==0 ~ "True_Negative",
                              allPredictions >= 50 & preserve==1 ~ "True_Positive",
                              allPredictions < 50 & preserve==1 ~ "False_Negative",
                              allPredictions >= 50 & preserve==0 ~ "False_Positive")) %>%
  ggplot()+
  geom_sf(aes(fill = confResult), color = "transparent")+
  scale_fill_manual(values = c("Red","Orange","Light Blue","Light Green"),
                    name="Outcomes")+
  labs(title="Confusion Metrics") +
  mapTheme

```
